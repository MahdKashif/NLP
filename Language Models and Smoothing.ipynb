{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Language Models and Smoothing"
      ],
      "metadata": {
        "id": "PbuMUu2HIdVA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os.path\n",
        "import sys\n",
        "import random\n",
        "from operator import itemgetter\n",
        "from collections import defaultdict\n",
        "from collections import Counter\n",
        "import random\n",
        "import math"
      ],
      "metadata": {
        "id": "vGixZQiAIUmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_corpus(file_path):\n",
        "    if os.path.isfile(file_path):\n",
        "        file = open(file_path, \"r\")\n",
        "        count = 0\n",
        "        corpus = []\n",
        "        print(\"Reading file \", file_path)\n",
        "        for line in file:\n",
        "            count += 1\n",
        "            sentence = line.split()\n",
        "            corpus.append(sentence)\n",
        "            if count % 1000 == 0:\n",
        "                sys.stderr.write(\"Reading sentence \" + str(count) + \"\\n\")\n",
        "        return corpus\n",
        "    else:\n",
        "        print(\"Error: corpus file \", file_path, \" does not exist\")\n",
        "        sys.exit()\n",
        "\n",
        "\n",
        "def preprocess_corpus(corpus):\n",
        "    word_freq = defaultdict(int)\n",
        "    for sentence in corpus:\n",
        "        for word in sentence:\n",
        "            word_freq[word] += 1\n",
        "\n",
        "    for sentence in corpus:\n",
        "        for i in range(0, len(sentence)):\n",
        "            word = sentence[i]\n",
        "            if word_freq[word] < 2:\n",
        "                sentence[i] = UNK\n",
        "\n",
        "    for sentence in corpus:\n",
        "        sentence.insert(0, START)\n",
        "        sentence.append(END)\n",
        "\n",
        "    return corpus\n",
        "\n",
        "\n",
        "def preprocess_test_data(vocabulary, test_corpus):\n",
        "    for sentence in test_corpus:\n",
        "        for i in range(0, len(sentence)):\n",
        "            word = sentence[i]\n",
        "            if word not in vocabulary:\n",
        "                sentence[i] = UNK\n",
        "\n",
        "    for sentence in test_corpus:\n",
        "        sentence.insert(0, START)\n",
        "        sentence.append(END)\n",
        "\n",
        "    return test_corpus\n",
        "\n",
        "UNK = \"UNK\"\n",
        "START = \"<s>\"\n",
        "END = \"</s>\"\n",
        "\n"
      ],
      "metadata": {
        "id": "JwaR7SaRj_NF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainCorpus = load_corpus('train.txt')\n",
        "trainCorpus = preprocess_corpus(trainCorpus)\n",
        "\n",
        "posTestCorpus = load_corpus('pos_test.txt')\n",
        "negTestCorpus = load_corpus('neg_test.txt')\n",
        "vocab = set(word for sentence in trainCorpus for word in sentence)\n",
        "\n",
        "posTestCorpus = preprocess_test_data(vocab, posTestCorpus)\n",
        "negTestCorpus = preprocess_test_data(vocab, negTestCorpus)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqj7v4CCk7IY",
        "outputId": "a1a29ece-5d60-4d39-822b-f44884b8da24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading file  train.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading sentence 1000\n",
            "Reading sentence 2000\n",
            "Reading sentence 3000\n",
            "Reading sentence 4000\n",
            "Reading sentence 5000\n",
            "Reading sentence 6000\n",
            "Reading sentence 7000\n",
            "Reading sentence 8000\n",
            "Reading sentence 9000\n",
            "Reading sentence 10000\n",
            "Reading sentence 11000\n",
            "Reading sentence 12000\n",
            "Reading sentence 13000\n",
            "Reading sentence 14000\n",
            "Reading sentence 15000\n",
            "Reading sentence 16000\n",
            "Reading sentence 17000\n",
            "Reading sentence 18000\n",
            "Reading sentence 19000\n",
            "Reading sentence 20000\n",
            "Reading sentence 21000\n",
            "Reading sentence 22000\n",
            "Reading sentence 23000\n",
            "Reading sentence 24000\n",
            "Reading sentence 25000\n",
            "Reading sentence 26000\n",
            "Reading sentence 27000\n",
            "Reading sentence 28000\n",
            "Reading sentence 29000\n",
            "Reading sentence 30000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading file  pos_test.txt\n",
            "Reading file  neg_test.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading sentence 1000\n",
            "Reading sentence 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unsmoothed Unigram"
      ],
      "metadata": {
        "id": "obVz-TqalRkt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UnigramModel:\n",
        "    def __init__(self):\n",
        "        self.vocab = set()\n",
        "        self.word_counts = defaultdict(int)\n",
        "        self.total_count = 0\n",
        "\n",
        "    def train_model(self, corpus):\n",
        "        for sentence in corpus:\n",
        "            for word in sentence:\n",
        "                self.word_counts[word] += 1\n",
        "                self.total_count += 1\n",
        "\n",
        "    def generate_sentence(self):\n",
        "        sentence = [\"<s>\"]\n",
        "        while True:\n",
        "            word = random.choices(list(self.word_counts.keys()), weights=list(self.word_counts.values()))[0]\n",
        "            sentence.append(word)\n",
        "            if word == \"</s>\":\n",
        "                break\n",
        "        return sentence\n",
        "\n",
        "    def get_sentence_probability(self, sentence):\n",
        "        probability = 1.0\n",
        "        for word in sentence:\n",
        "            probability *= self.word_counts[word] / self.total_count\n",
        "        return probability\n",
        "\n",
        "    def generate_sentences_to_file(self, file_name, num_sentences):\n",
        "        file_pointer = open(file_name, 'w+')\n",
        "        for i in range(num_sentences):\n",
        "            sen = self.generate_sentence()\n",
        "            prob = self.get_sentence_probability(sen)\n",
        "            string_generated = str(prob) + \" \" + \" \".join(sen)\n",
        "            print(string_generated, end=\"\\n\", file=file_pointer)\n",
        "\n",
        "    def compute_perplexity(self, test_corpus):\n",
        "        total_log_probability = 0\n",
        "        total_words = 0\n",
        "\n",
        "        for sentence in test_corpus:\n",
        "            sentence_probability = self.get_sentence_probability(sentence)\n",
        "            total_words += len(sentence)\n",
        "\n",
        "            if sentence_probability > 0:\n",
        "                total_log_probability += math.log(sentence_probability)\n",
        "\n",
        "        perplexity = math.exp(-total_log_probability / total_words)\n",
        "        return perplexity\n"
      ],
      "metadata": {
        "id": "31vDvLnUlG1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = UnigramModel()\n",
        "model.train_model(trainCorpus)\n",
        "model.generate_sentences_to_file('unigram output.txt',20)\n",
        "print(model.compute_perplexity(posTestCorpus))\n",
        "print(model.compute_perplexity(negTestCorpus))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDLaJvS5lLo_",
        "outputId": "9b141563-7437-426a-9a95-5a7ce879fb40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "579.0175572073653\n",
            "561.6252784519507\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "smoothed Unigram"
      ],
      "metadata": {
        "id": "UMNG2CSalTWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SmoothedUnigramModel:\n",
        "    def __init__(self):\n",
        "        self.vocab = set()\n",
        "        self.word_counts = defaultdict(int)\n",
        "        self.total_count = 0\n",
        "\n",
        "    def train_model(self, corpus):\n",
        "        for sentence in corpus:\n",
        "            for word in sentence:\n",
        "                self.word_counts[word] += 1\n",
        "                self.total_count += 1\n",
        "\n",
        "        self.vocab = set(self.word_counts.keys())\n",
        "\n",
        "    def generate_sentence(self):\n",
        "        sentence = [\"<s>\"]\n",
        "        while True:\n",
        "            word = random.choices(list(self.word_counts.keys()), weights=list(self.word_counts.values()))[0]\n",
        "            sentence.append(word)\n",
        "            if word == \"</s>\":\n",
        "                break\n",
        "        return sentence\n",
        "\n",
        "    def get_sentence_probability(self, sentence):\n",
        "        probability = 1.0\n",
        "        vocabulary_size = len(self.vocab)\n",
        "        for word in sentence:\n",
        "            probability *= (self.word_counts[word] + 1) / (self.total_count + vocabulary_size)\n",
        "        return probability\n",
        "\n",
        "    def generate_sentences_to_file(self, file_name, num_sentences):\n",
        "        file_pointer = open(file_name, 'w+')\n",
        "        for i in range(num_sentences):\n",
        "            sen = self.generate_sentence()\n",
        "            prob = self.get_sentence_probability(sen)\n",
        "            string_generated = str(prob) + \" \" + \" \".join(sen)\n",
        "            print(string_generated, end=\"\\n\", file=file_pointer)\n",
        "\n",
        "    def compute_perplexity(self, test_corpus):\n",
        "        total_log_probability = 0\n",
        "        total_words = 0\n",
        "\n",
        "        for sentence in test_corpus:\n",
        "            sentence_probability = self.get_sentence_probability(sentence)\n",
        "            total_words += len(sentence)\n",
        "\n",
        "            if sentence_probability > 0:\n",
        "                total_log_probability += math.log(sentence_probability)\n",
        "\n",
        "        perplexity = math.exp(-total_log_probability / total_words)\n",
        "        return perplexity"
      ],
      "metadata": {
        "id": "_Ts_9xV1lZ0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SmoothedUnigramModel()\n",
        "model.train_model(trainCorpus)\n",
        "model.generate_sentences_to_file('smooth unigram output.txt',20)\n",
        "print(model.compute_perplexity(posTestCorpus))\n",
        "print(model.compute_perplexity(negTestCorpus))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYPy4eSelb0f",
        "outputId": "beedc38d-3397-4eb3-97fc-cffbeae22bbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "581.5700463677365\n",
            "564.3740498208495\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unsmoothed Bigram"
      ],
      "metadata": {
        "id": "qA3WChnNlitx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UnsmoothedBigramModel:\n",
        "    def __init__(self):\n",
        "        self.vocab = set()\n",
        "        self.bigram_counts = defaultdict(lambda: defaultdict(int))\n",
        "        self.unigram_counts = defaultdict(int)\n",
        "        self.total_count = 0\n",
        "\n",
        "    def train_model(self, corpus):\n",
        "        for sentence in corpus:\n",
        "            for i in range(len(sentence) - 1):\n",
        "                word1, word2 = sentence[i], sentence[i + 1]\n",
        "                self.bigram_counts[word1][word2] += 1\n",
        "                self.unigram_counts[word1] += 1\n",
        "                self.total_count += 1\n",
        "            self.unigram_counts[sentence[-1]] += 1\n",
        "            self.total_count += 1\n",
        "        self.vocab = set(self.unigram_counts.keys())\n",
        "\n",
        "    def generate_sentence(self):\n",
        "        sentence = [\"<s>\"]\n",
        "        while True:\n",
        "            prev_word = sentence[-1]\n",
        "            next_word = random.choices(list(self.bigram_counts[prev_word].keys()))[0]\n",
        "            sentence.append(next_word)\n",
        "            if next_word == \"</s>\":\n",
        "                break\n",
        "        return sentence\n",
        "\n",
        "    def get_sentence_probability(self, sentence):\n",
        "        probability = 1.0\n",
        "        for i in range(len(sentence) - 1):\n",
        "            word1, word2 = sentence[i], sentence[i + 1]\n",
        "            bigram_count = self.bigram_counts[word1][word2]\n",
        "            unigram_count = self.unigram_counts[word1]\n",
        "            if unigram_count == 0:\n",
        "                return 0\n",
        "            probability *= bigram_count / unigram_count\n",
        "        return probability\n",
        "\n",
        "    def generate_sentences_to_file(self, file_name, num_sentences):\n",
        "        file_pointer = open(file_name, 'w+')\n",
        "        for i in range(num_sentences):\n",
        "            sen = self.generate_sentence()\n",
        "            prob = self.get_sentence_probability(sen)\n",
        "            string_generated = str(prob) + \" \" + \" \".join(sen)\n",
        "            print(string_generated, end=\"\\n\", file=file_pointer)\n",
        "\n",
        "    def compute_perplexity(self, test_corpus):\n",
        "        total_log_probability = 0\n",
        "        total_words = 0\n",
        "\n",
        "        for sentence in test_corpus:\n",
        "            sentence_probability = self.get_sentence_probability(sentence)\n",
        "            total_words += len(sentence)\n",
        "            if sentence_probability > 0:\n",
        "                total_log_probability += math.log(sentence_probability)\n",
        "\n",
        "        perplexity = math.exp(-total_log_probability / total_words)\n",
        "        return perplexity"
      ],
      "metadata": {
        "id": "OB4H8vd1lfBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = UnsmoothedBigramModel()\n",
        "model.train_model(trainCorpus)\n",
        "model.generate_sentences_to_file('bigram output.txt',20)\n",
        "print(model.compute_perplexity(posTestCorpus))\n",
        "print(model.compute_perplexity(negTestCorpus))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5_eYrf4lpga",
        "outputId": "528df753-47cd-4b4f-ef18-9fde14ace48e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0870673514925697\n",
            "1.107624965768465\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Smoothed Bigram"
      ],
      "metadata": {
        "id": "vliWtPgdltCF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SmoothedBigramModel:\n",
        "    def __init__(self, smoothing_parameter=0.5):\n",
        "        self.vocab = set()\n",
        "        self.bigram_counts = defaultdict(lambda: defaultdict(int))\n",
        "        self.unigram_counts = defaultdict(int)\n",
        "        self.total_count = 0\n",
        "        self.smoothing_parameter = smoothing_parameter\n",
        "\n",
        "    def train_model(self, corpus):\n",
        "        for sentence in corpus:\n",
        "            for i in range(len(sentence) - 1):\n",
        "                word1, word2 = sentence[i], sentence[i + 1]\n",
        "                self.bigram_counts[word1][word2] += 1\n",
        "                self.unigram_counts[word1] += 1\n",
        "                self.total_count += 1\n",
        "            self.unigram_counts[sentence[-1]] += 1\n",
        "            self.total_count += 1\n",
        "        self.vocab = set(self.unigram_counts.keys())\n",
        "\n",
        "    def generate_sentence(self):\n",
        "        sentence = [\"<s>\"]\n",
        "        while True:\n",
        "            prev_word = sentence[-1]\n",
        "            next_word = random.choices(list(self.bigram_counts[prev_word].keys()))[0]\n",
        "            sentence.append(next_word)\n",
        "            if next_word == \"</s>\" or len(sentence) > 20:\n",
        "                break\n",
        "        return sentence\n",
        "\n",
        "    def get_sentence_probability(self, sentence):\n",
        "        probability = 1.0\n",
        "        for i in range(len(sentence) - 1):\n",
        "            word1, word2 = sentence[i], sentence[i + 1]\n",
        "            bigram_count = self.bigram_counts[word1][word2]\n",
        "            unigram_count = self.unigram_counts[word1]\n",
        "            if unigram_count == 0:\n",
        "                return 0\n",
        "\n",
        "            bigram_prob = bigram_count / unigram_count\n",
        "            unigram_prob = self.unigram_counts[word2] / self.total_count\n",
        "            probability *= self.smoothing_parameter * bigram_prob + (1 - self.smoothing_parameter) * unigram_prob\n",
        "        return probability\n",
        "\n",
        "    def generate_sentences_to_file(self, file_name, num_sentences):\n",
        "        file_pointer = open(file_name, 'w+')\n",
        "        for i in range(num_sentences):\n",
        "            sen = self.generate_sentence()\n",
        "            prob = self.get_sentence_probability(sen)\n",
        "            string_generated = str(prob) + \" \" + \" \".join(sen)\n",
        "            print(string_generated, end=\"\\n\", file=file_pointer)\n",
        "\n",
        "    def compute_perplexity(self, test_corpus):\n",
        "        total_log_probability = 0\n",
        "        total_words = 0\n",
        "\n",
        "        for sentence in test_corpus:\n",
        "            sentence_probability = self.get_sentence_probability(sentence)\n",
        "            total_words += len(sentence)\n",
        "            if sentence_probability > 0:\n",
        "                total_log_probability += math.log(sentence_probability)\n",
        "\n",
        "        perplexity = math.exp(-total_log_probability / total_words)\n",
        "        return perplexity"
      ],
      "metadata": {
        "id": "0zTVRa7DltyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SmoothedBigramModel()\n",
        "model.train_model(trainCorpus)\n",
        "model.generate_sentences_to_file('smoothed bigram output.txt',20)\n",
        "print(model.compute_perplexity(posTestCorpus))\n",
        "print(model.compute_perplexity(negTestCorpus))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZDwnbHflxSz",
        "outputId": "19d11b90-1314-48c1-d52e-d701f7ccf18a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200.96697839328772\n",
            "205.37508966186493\n"
          ]
        }
      ]
    }
  ]
}