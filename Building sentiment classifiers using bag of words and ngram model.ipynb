{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MkqexFxxVOKh"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.preprocessing import label_binarize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7ipdhfXZVOKl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "file = '/content/Q2 Sentiment Analysis Dataset.csv'\n",
        "data = pd.read_csv(file, delimiter=',', encoding='latin1')\n",
        "data = data.iloc[:, :-1]\n",
        "\n",
        "reviews = data['text'].tolist()\n",
        "labels = data['sentiment'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fRfxxU1pVOKm"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(reviews, labels, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xPUtVwUEVOKn"
      },
      "outputs": [],
      "source": [
        "count = CountVectorizer()\n",
        "X_train_counts = count.fit_transform(X_train)\n",
        "X_test_counts = count.transform(X_test)\n",
        "\n",
        "tfidf = TfidfVectorizer()\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "\n",
        "ngram = CountVectorizer(ngram_range=(1, 3))\n",
        "X_train_ngrams = ngram.fit_transform(X_train)\n",
        "X_test_ngrams = ngram.transform(X_test)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3ra1QhCVOKn",
        "outputId": "57600ce6-9d9e-4c0e-e7c9-6513459e259b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('MultinomialNB', 'Bag of Words (Raw Counts)', 0.7264150943396226, 0.5252534259186196, 0.7264150943396226, 0.43624944543034605, 0.7264150943396226, 0.4358368960960194, 0.7264150943396227)\n",
            "('MultinomialNB', 'Bag of Words (TfIDF)', 0.7401372212692967, 0.6271551334237901, 0.7401372212692967, 0.41329858030168587, 0.7401372212692967, 0.40909701594194625, 0.7401372212692968)\n",
            "('MultinomialNB', 'N-gram', 0.7367066895368782, 0.5152689590049168, 0.7367066895368782, 0.43668235636645963, 0.7367066895368782, 0.43726326662982545, 0.7367066895368782)\n",
            "('LogisticRegression', 'Bag of Words (Raw Counts)', 0.7324185248713551, 0.5102120146477563, 0.7324185248713551, 0.44846765472493344, 0.7324185248713551, 0.46110207982252976, 0.7324185248713551)\n",
            "('LogisticRegression', 'Bag of Words (TfIDF)', 0.7375643224699828, 0.5767353338207998, 0.7375643224699828, 0.43961741625998224, 0.7375643224699828, 0.45336816031586397, 0.7375643224699828)\n",
            "('LogisticRegression', 'N-gram', 0.7272727272727273, 0.5175842704556037, 0.7272727272727273, 0.4346827861579415, 0.7272727272727273, 0.4450379060248259, 0.7272727272727273)\n",
            "('RandomForestClassifier', 'Bag of Words (Raw Counts)', 0.7289879931389366, 0.5304023845007452, 0.7289879931389366, 0.4326922277062999, 0.7289879931389366, 0.44351219663283503, 0.7289879931389367)\n",
            "('RandomForestClassifier', 'Bag of Words (TfIDF)', 0.7144082332761578, 0.4959631404770055, 0.7144082332761578, 0.4130743261978705, 0.7144082332761578, 0.4152822776244404, 0.7144082332761578)\n",
            "('RandomForestClassifier', 'N-gram', 0.7246998284734134, 0.5546471258708454, 0.7246998284734134, 0.42415358806566106, 0.7246998284734134, 0.43390354316602, 0.7246998284734134)\n",
            "('SVC', 'Bag of Words (Raw Counts)', 0.7195540308747856, 0.5661471452560873, 0.7195540308747856, 0.4085854314551908, 0.7195540308747856, 0.40905742109452997, 0.7195540308747855)\n",
            "('SVC', 'Bag of Words (TfIDF)', 0.7392795883361921, 0.6042162353026588, 0.7392795883361921, 0.4355430623336291, 0.7392795883361921, 0.4469600827202752, 0.739279588336192)\n",
            "('SVC', 'N-gram', 0.7135506003430532, 0.5631520966595593, 0.7135506003430532, 0.4036268855368234, 0.7135506003430532, 0.40458425618973975, 0.7135506003430532)\n",
            "('Perceptron', 'Bag of Words (Raw Counts)', 0.7341337907375644, 0.5133010626880175, 0.7341337907375644, 0.4626868206521739, 0.7341337907375644, 0.4776330127015356, 0.7341337907375644)\n",
            "('Perceptron', 'Bag of Words (TfIDF)', 0.7289879931389366, 0.5401626514907766, 0.7289879931389366, 0.4845850797412786, 0.7289879931389366, 0.5025086681494286, 0.7289879931389367)\n",
            "('Perceptron', 'N-gram', 0.6903945111492281, 0.5034878323799156, 0.6903945111492281, 0.4285658828748891, 0.6903945111492281, 0.4327592168595963, 0.6903945111492281)\n"
          ]
        }
      ],
      "source": [
        "def evaluate(classifier, X_train, y_train, X_test, y_test):\n",
        "\n",
        "    classifier.fit(X_train, y_train)\n",
        "    y_pred = classifier.predict(X_test)\n",
        "    #acc= accuracy_score(y_pred,y_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision_macro = precision_score(y_test, y_pred, average='macro')\n",
        "    precision_micro = precision_score(y_test, y_pred, average='micro')\n",
        "    recall_macro = recall_score(y_test, y_pred, average='macro')\n",
        "    recall_micro = recall_score(y_test, y_pred, average='micro')\n",
        "    f_score_macro = f1_score(y_test, y_pred, average='macro')\n",
        "    f_score_micro = f1_score(y_test, y_pred, average='micro')\n",
        "\n",
        "    return accuracy, precision_macro, precision_micro, recall_macro, recall_micro, f_score_macro, f_score_micro\n",
        "\n",
        "\n",
        "naive_bayes = MultinomialNB()\n",
        "logistic_regression = LogisticRegression()\n",
        "random_forest = RandomForestClassifier()\n",
        "svm = SVC()\n",
        "perceptron = Perceptron()\n",
        "\n",
        "\n",
        "classifiers = [naive_bayes, logistic_regression, random_forest, svm, perceptron]\n",
        "vectorizers = ['Bag of Words (Raw Counts)', 'Bag of Words (TfIDF)', 'N-gram']\n",
        "results = []\n",
        "\n",
        "\n",
        "for classifier in classifiers:\n",
        "    for vectorizer in vectorizers:\n",
        "        if vectorizer == 'Bag of Words (Raw Counts)':\n",
        "            accuracy, precision_macro, precision_micro, recall_macro, recall_micro, f_score_macro, f_score_micro = evaluate(classifier, X_train_counts, y_train, X_test_counts, y_test)\n",
        "        if vectorizer == 'N-gram':\n",
        "            accuracy, precision_macro, precision_micro, recall_macro, recall_micro, f_score_macro, f_score_micro = evaluate(classifier, X_train_ngrams, y_train, X_test_ngrams, y_test)\n",
        "        elif vectorizer == 'Bag of Words (TfIDF)':\n",
        "            accuracy, precision_macro, precision_micro, recall_macro, recall_micro, f_score_macro, f_score_micro = evaluate(classifier, X_train_tfidf, y_train, X_test_tfidf, y_test)\n",
        "\n",
        "        results.append((classifier.__class__.__name__, vectorizer, accuracy, precision_macro, precision_micro, recall_macro, recall_micro, f_score_macro, f_score_micro))\n",
        "\n",
        "for result in results:\n",
        "  print(result)"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}